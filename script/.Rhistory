# Import packages
library(here)
library(tidyverse)
# Read in csv
shopify_data <- read_csv(here("2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
shopify_data$order_amount # review the order_amount column
checkNA <- is.na(shopify_data) # check for any NA values in the data set
shopifyaveragevalue <- mean(shopify_data$order_amount) # This is the original way Shopify used to calculate the average order value
sort(shopify_data$order_amount, decreasing = T) # Dataset has large values upon reviewing the entire order_amount column
# Clean up
sneakers <- shopify_data %>%
group_by(shop_id) %>%
mutate(shop_count = n()) %>% #counts the number of times a user_id has bought items at that shop_id
summarise(AverageStoreValue = mean(rep(order_amount)))%>% # Find the mean for each store
group_by(AverageStoreValue) %>%
arrange(desc(AverageStoreValue)) # Sort by decreasing
# Plot
ggplot(data = sneakers, mapping = aes(x = shop_id, AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop identification",
x = "Shop Identification Number",
y = "Average order value",
size = "Store value by size") +
guides(colour = FALSE)
# Check and remove outliers
sneaker_outliers <- sneakers %>%
mutate(AverageStoreValue = sort(AverageStoreValue, decreasing = T)) %>% # You can see there are 2 outliers when we look at the ascending to descending values of the average store
filter(!AverageStoreValue > 1000) # Filter stores out that have an AverageStoreValue greater than 1000
# Plot the new data
ggplot(data = sneaker_outliers, mapping = aes(x = shop_id, AverageStoreValue, color = AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Average order value by size",
color = "Order amount")
sneaker_median <- median(shopify_data$order_amount)
# Plot
ggplot(data = sneakers, mapping = aes(x = shop_id, AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Store value by size") +
guides(colour = FALSE)
# Plot the new data
ggplot(data = sneaker_outliers, mapping = aes(x = shop_id, AverageStoreValue, color = AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Average order value by size",
color = "Order amount")
# Import packages
library(here)
library(tidyverse)
# Read in csv
shopify_data <- read_csv(here("2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
shopify_data$order_amount # review the order_amount column
checkNA <- is.na(shopify_data) # check for any NA values in the data set
shopifyaveragevalue <- mean(shopify_data$order_amount) # This is the original way Shopify used to calculate the average order value
sort(shopify_data$order_amount, decreasing = T) # Dataset has large values upon reviewing the entire order_amount column
# Clean up
sneakers <- shopify_data %>%
group_by(shop_id) %>%
mutate(shop_count = n()) %>% #counts the number of times a user_id has bought items at that shop_id
summarise(AverageStoreValue = mean(rep(order_amount)))%>% # Find the mean for each store
group_by(AverageStoreValue) %>%
arrange(desc(AverageStoreValue)) # Sort by decreasing
# Plot
ggplot(data = sneakers, mapping = aes(x = shop_id, AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Store value by size") +
guides(colour = FALSE)
# Check and remove outliers
sneaker_outliers <- sneakers %>%
mutate(AverageStoreValue = sort(AverageStoreValue, decreasing = T)) %>% # You can see there are 2 outliers when we look at the ascending to descending values of the average store
filter(!AverageStoreValue > 1000) # Filter stores out that have an AverageStoreValue greater than 1000
# Plot the new data
ggplot(data = sneaker_outliers, mapping = aes(x = shop_id, AverageStoreValue, color = AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Average order value by size",
color = "Order amount")
sneaker_median <- median(shopify_data$order_amount)
# Read in csv
shopify_data <- read_csv(here("data/2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
# Import packages
library(here)
library(tidyverse)
# Read in csv
shopify_data <- read_csv(here("data/2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
# Read in csv
shopify_data <- read_csv(here("data/2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
# Read in csv
shopify_data <- read_csv(here("scripts/data/2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
# Read in csv
shopify_data <- read_csv(here("script/data/2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
shopify_data$order_amount # review the order_amount column
checkNA <- is.na(shopify_data) # check for any NA values in the data set
shopifyaveragevalue <- mean(shopify_data$order_amount) # This is the original way Shopify used to calculate the average order value
sort(shopify_data$order_amount, decreasing = T) # Dataset has large values upon reviewing the entire order_amount column
# Clean up
sneakers <- shopify_data %>%
group_by(shop_id) %>%
mutate(shop_count = n()) %>% #counts the number of times a user_id has bought items at that shop_id
summarise(AverageStoreValue = mean(rep(order_amount)))%>% # Find the mean for each store
group_by(AverageStoreValue) %>%
arrange(desc(AverageStoreValue)) # Sort by decreasing
# Plot
ggplot(data = sneakers, mapping = aes(x = shop_id, AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Store value by size") +
guides(colour = FALSE)
# Check and remove outliers
sneaker_outliers <- sneakers %>%
mutate(AverageStoreValue = sort(AverageStoreValue, decreasing = T)) %>% # You can see there are 2 outliers when we look at the ascending to descending values of the average store
filter(!AverageStoreValue > 1000) # Filter stores out that have an AverageStoreValue greater than 1000
# Plot the new data
ggplot(data = sneaker_outliers, mapping = aes(x = shop_id, AverageStoreValue, color = AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Average order value by size",
color = "Order amount")
sneaker_median <- median(shopify_data$order_amount)
# Read in csv
shopify_data <- read_csv(here("script/data/2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
shopify_data$order_amount # review the order_amount column
checkNA <- is.na(shopify_data) # check for any NA values in the data set
# Import packages
library(here)
library(tidyverse)
# Read in csv
shopify_data <- read_csv(here("script/data/2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
shopify_data$order_amount # review the order_amount column
checkNA <- is.na(shopify_data) # check for any NA values in the data set
shopifyaveragevalue <- mean(shopify_data$order_amount) # This is the original way Shopify used to calculate the average order value
sort(shopify_data$order_amount, decreasing = T) # Dataset has large values upon reviewing the entire order_amount column
# Clean up
sneakers <- shopify_data %>%
group_by(shop_id) %>%
mutate(shop_count = n()) %>% #counts the number of times a user_id has bought items at that shop_id
summarise(AverageStoreValue = mean(rep(order_amount)))%>% # Find the mean for each store
group_by(AverageStoreValue) %>%
arrange(desc(AverageStoreValue)) # Sort by decreasing
# Plot
ggplot(data = sneakers, mapping = aes(x = shop_id, AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Store value by size") +
guides(colour = FALSE)
# Check and remove outliers
sneaker_outliers <- sneakers %>%
mutate(AverageStoreValue = sort(AverageStoreValue, decreasing = T)) %>% # You can see there are 2 outliers when we look at the ascending to descending values of the average store
filter(!AverageStoreValue > 1000) # Filter stores out that have an AverageStoreValue greater than 1000
# Plot the new data
ggplot(data = sneaker_outliers, mapping = aes(x = shop_id, AverageStoreValue, color = AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Average order value by size",
color = "Order amount")
sneaker_median <- median(shopify_data$order_amount)
sneaker_median <- median(shopify_data$order_amount)
# Plot the new data
ggplot(data = sneaker_outliers, mapping = aes(x = shop_id, AverageStoreValue, color = AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Average order value by size",
color = "Order amount")
# Import packages
library(here)
library(tidyverse)
# Read in csv
shopify_data <- read_csv(here("script/data/2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv"))
shopify_data$order_amount # review the order_amount column
checkNA <- is.na(shopify_data) # check for any NA values in the data set
shopifyaveragevalue <- mean(shopify_data$order_amount) # This is the original way Shopify used to calculate the average order value
sort(shopify_data$order_amount, decreasing = T) # Dataset has large values upon reviewing the entire order_amount column
# Clean up
sneakers <- shopify_data %>%
group_by(shop_id) %>%
mutate(shop_count = n()) %>% #counts the number of times a user_id has bought items at that shop_id
summarise(AverageStoreValue = mean(rep(order_amount)))%>% # Find the mean for each store
group_by(AverageStoreValue) %>%
arrange(desc(AverageStoreValue)) # Sort by decreasing
# Plot
ggplot(data = sneakers, mapping = aes(x = shop_id, AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Store value by size") +
guides(colour = FALSE)
# Check and remove outliers
sneaker_outliers <- sneakers %>%
mutate(AverageStoreValue = sort(AverageStoreValue, decreasing = T)) %>% # You can see there are 2 outliers when we look at the ascending to descending values of the average store
filter(!AverageStoreValue > 1000) # Filter stores out that have an AverageStoreValue greater than 1000
# Plot the new data
ggplot(data = sneaker_outliers, mapping = aes(x = shop_id, AverageStoreValue, color = AverageStoreValue, size = AverageStoreValue)) +
geom_point() +
labs(title = "Average order value of sneakers by shop",
x = "Shop Identification Number",
y = "Average order value",
size = "Average order value by size",
color = "Order amount")
sneaker_median <- median(shopify_data$order_amount)
